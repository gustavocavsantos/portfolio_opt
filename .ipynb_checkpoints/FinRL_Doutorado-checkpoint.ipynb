{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL/blob/master/tutorials/1-Introduction/FinRL_PortfolioAllocation_NeurIPS_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yv3IDvrobU37"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Portfolio Allocation\n",
    "\n",
    "Tutorials to use OpenAI DRL to perform portfolio allocation in one Jupyter Notebook | Presented at NeurIPS 2020: Deep RL Workshop\n",
    "\n",
    "* This blog is based on our paper: FinRL: A Deep Reinforcement Learning Library for Automated Stock Trading in Quantitative Finance, presented at NeurIPS 2020: Deep RL Workshop.\n",
    "* Check out medium blog for detailed explanations: \n",
    "* Please report any issues to our Github: https://github.com/AI4Finance-Foundation/FinRL/issues\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kHCfEiTA80V"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUmLTmoQA7_w"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12v1i0jVkg48"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L63HKnWvkirx"
   },
   "source": [
    "This problem is to design an automated trading solution for portfolio alloacation. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A represents the weight of a stock in the porfolio: a ∈ (-1,1). Assume our stock pool includes N stocks, we can use a list [a<sub>1</sub>, a<sub>2</sub>, ... , a<sub>N</sub>] to determine the weight for each stock in the porfotlio, where a<sub>i</sub> ∈ (-1,1), a<sub>1</sub>+ a<sub>2</sub>+...+a<sub>N</sub>=1. For example, \"The weight of AAPL in the portfolio is 10%.\" is [0.1 , ...].\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_emqQCCklVt"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVCcCalAknGn"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pT8a0fvhA_TW",
    "outputId": "1eba9a59-ff73-47c1-bfd9-d32ea43c0a5c",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "## install finrl library\n",
    "#%pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2568cp5bU38"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNmvYN9YbU4B"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ntfTb0e2bU4C",
    "outputId": "2267190b-fe54-43a3-8d03-893d02a20f39",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gustavo/anaconda3/envs/finrl/lib/python3.7/site-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"
     ]
    }
   ],
   "source": [
    "import talib as ta\n",
    "from utils import process_future_data, dates_intersection, add_covariance, StockPortfolioEnv, create_features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "\n",
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "from finrl.finrl_meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.finrl_meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.finrl_meta.env_portfolio_allocation.env_portfolio import StockPortfolioEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline,convert_daily_return_to_pyfolio_ts\n",
    "from finrl.finrl_meta.data_processor import DataProcessor\n",
    "from finrl.finrl_meta.data_processors.processor_yahoofinance import YahooFinanceProcessor\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlIS2abxkwan"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "B8bBq7nsBCfF",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slBria_QbU4F"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrz = process_future_data('data/ARROZ.csv')\n",
    "bg   = process_future_data('data/BOI_GORDO.csv')\n",
    "cf   = process_future_data('data/CAFE.csv')\n",
    "eth  = process_future_data('data/ETANOL.csv')\n",
    "mil  = process_future_data('data/MILHO.csv')\n",
    "mf   = process_future_data('data/MINERIO_FERRO.csv')\n",
    "gold = process_future_data('data/OURO.csv')\n",
    "petr = process_future_data('data/PETROLEO.csv')\n",
    "soj  = process_future_data('data/SOJA.csv')\n",
    "trg  = process_future_data('data/TRIGO.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmds_f =pd.concat([arrz,bg,cf,eth,mil,mf,gold,petr,soj,trg],axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ZR', 'LE', 'KC', 'FL', 'ZC', 'TR', 'GC', 'CB', 'ZS', 'ZW']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmds_f['tic'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmds_f_l = cmds_f[\"tic\"].unique().tolist()\n",
    "stocks_br  = [\"PETR4.SA\", \"VALE3.SA\", \"ITUB4.SA\", \"MGLU3.SA\", \"BBAS3.SA\", \"BBDC4.SA\",\"B3SA3.SA\", \"PETR3.SA\", \"RENT3.SA\", \"ELET3.SA\" ]\n",
    "stocks_usa = [\"META\", \"AAPL\", \"AMZN\", \"F\", \"T\", \"BAC\", \"GOOGL\", \"MSFT\", \"INTC\", \"CMCSA\"]\n",
    "stocks_eur = [\"iSP.MI\", \"ENEL.MI\", \"SAN.MC\", \"INGA.AS\", \"ENI.MI\", \"BBVA.MC\", \"IBE.MC\", \"CS.PA\", \"STLA.MI\",\"DTE.DE\"]\n",
    "stocks_chn = [\"601899.SS\",\"600010.SS\",\"600795.SS\", \"603993.SS\", \"600157.SS\", \"601288.SS\", \"600050.SS\", \"601398.SS\", \"600537.SS\",\"600777.SS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ativos = list(set().union(stocks_br,stocks_usa,stocks_eur,stocks_chn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ativos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CPsuy6d9yRPp",
    "outputId": "5f9be2b1-c3f9-4205-a753-a81a1d793d17",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#print(config_tickers.DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WEwzMkFHbU4G",
    "outputId": "8db19feb-cf14-418f-d6d4-99aeb0bfa6ef",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (175832, 9)\n"
     ]
    }
   ],
   "source": [
    "dp = YahooFinanceProcessor()\n",
    "df = dp.download_data(start_date = '2004-01-01',\n",
    "                     end_date = '2022-11-07',\n",
    "                     ticker_list = ativos, time_interval='1D')\n",
    "ativos = ativos = list(set().union(stocks_br,stocks_usa,stocks_eur,stocks_chn,cmds_f_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,cmds_f],axis=0)\n",
    "df['date']= pd.to_datetime(df['date'])\n",
    "df = df.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9UwKwzRbU4l"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qz9K2vul6RmK"
   },
   "source": [
    "## Add covariance matrix as states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_covariance(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qz9K2vul6RmK"
   },
   "source": [
    "## Adding Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223396, 21)\n",
      "(110050, 21)\n"
     ]
    }
   ],
   "source": [
    "dates_f3 = dates_intersection(df)\n",
    "print(df.shape)\n",
    "df=df[df['date'].isin(dates_f3)]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['tic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_zsIW1LAiqCb",
    "outputId": "080be760-c4b2-4115-db37-b132cd482971",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110050, 21)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UooHj1OgbU4v"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103420   2013-01-04\n",
      "Name: date, dtype: datetime64[ns]\n",
      "226101   2022-10-27\n",
      "Name: date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(df.date.head(1))\n",
    "print(df.date.tail(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQnmN1qdk88I"
   },
   "source": [
    "## Training data split: 2009-01-01 to 2020-07-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "NrPxgv4eBQ_R",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train = data_split(df, '2013-01-04','2018-01-01')\n",
    "trade = data_split(df,'2018-01-02', '2022-10-27')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "vU2vXEll0hfk",
    "outputId": "e8c76dfd-2c43-4f60-8eee-a1a4f564eed6",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjcp</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>...</th>\n",
       "      <th>RSI</th>\n",
       "      <th>slowk</th>\n",
       "      <th>slowd</th>\n",
       "      <th>WILLR</th>\n",
       "      <th>MACD</th>\n",
       "      <th>ROC</th>\n",
       "      <th>OBV</th>\n",
       "      <th>lag_20</th>\n",
       "      <th>lag_40</th>\n",
       "      <th>lag_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>1.975</td>\n",
       "      <td>1.985714</td>\n",
       "      <td>1.928571</td>\n",
       "      <td>1.942857</td>\n",
       "      <td>1.899315</td>\n",
       "      <td>214400818.0</td>\n",
       "      <td>600010.SS</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.0007838344569130899, 8.932580553651602e-05...</td>\n",
       "      <td>...</td>\n",
       "      <td>59.497655</td>\n",
       "      <td>53.365166</td>\n",
       "      <td>49.616944</td>\n",
       "      <td>-23.863621</td>\n",
       "      <td>0.03241</td>\n",
       "      <td>3.03031</td>\n",
       "      <td>6.918310e+10</td>\n",
       "      <td>0.182609</td>\n",
       "      <td>-0.003663</td>\n",
       "      <td>0.04817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   open      high       low     close     adjcp       volume  \\\n",
       "0 2013-01-04  1.975  1.985714  1.928571  1.942857  1.899315  214400818.0   \n",
       "\n",
       "         tic  day                                           cov_list  ...  \\\n",
       "0  600010.SS    4  [[0.0007838344569130899, 8.932580553651602e-05...  ...   \n",
       "\n",
       "         RSI      slowk      slowd      WILLR     MACD      ROC           OBV  \\\n",
       "0  59.497655  53.365166  49.616944 -23.863621  0.03241  3.03031  6.918310e+10   \n",
       "\n",
       "     lag_20    lag_40   lag_60  \n",
       "0  0.182609 -0.003663  0.04817  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjcp</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>...</th>\n",
       "      <th>RSI</th>\n",
       "      <th>slowk</th>\n",
       "      <th>slowd</th>\n",
       "      <th>WILLR</th>\n",
       "      <th>MACD</th>\n",
       "      <th>ROC</th>\n",
       "      <th>OBV</th>\n",
       "      <th>lag_20</th>\n",
       "      <th>lag_40</th>\n",
       "      <th>lag_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>2.794</td>\n",
       "      <td>2.796</td>\n",
       "      <td>2.754</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1.723731</td>\n",
       "      <td>73906621.0</td>\n",
       "      <td>iSP.MI</td>\n",
       "      <td>4</td>\n",
       "      <td>[[0.0002780890201951984, 4.7102876631634787e-0...</td>\n",
       "      <td>...</td>\n",
       "      <td>42.279556</td>\n",
       "      <td>34.823964</td>\n",
       "      <td>59.120869</td>\n",
       "      <td>-87.368462</td>\n",
       "      <td>-0.007944</td>\n",
       "      <td>-3.551532</td>\n",
       "      <td>6.916249e+09</td>\n",
       "      <td>-0.01773</td>\n",
       "      <td>-0.037526</td>\n",
       "      <td>-0.055896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   open   high    low  close     adjcp      volume     tic  \\\n",
       "1127 2017-12-29  2.794  2.796  2.754   2.77  1.723731  73906621.0  iSP.MI   \n",
       "\n",
       "      day                                           cov_list  ...        RSI  \\\n",
       "1127    4  [[0.0002780890201951984, 4.7102876631634787e-0...  ...  42.279556   \n",
       "\n",
       "          slowk      slowd      WILLR      MACD       ROC           OBV  \\\n",
       "1127  34.823964  59.120869 -87.368462 -0.007944 -3.551532  6.916249e+09   \n",
       "\n",
       "       lag_20    lag_40    lag_60  \n",
       "1127 -0.01773 -0.037526 -0.055896  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxQTNjpblAMN"
   },
   "source": [
    "## Environment for Portfolio Allocation\n",
    "##### Got from utils.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MzD06X0CbU43",
    "outputId": "ab17eecd-2079-4684-a793-0541088b1c00",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 50, State Space: 50\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features =['RSI', 'slowk', 'slowd', 'WILLR', 'MACD','ROC', 'OBV', 'lag_20', 'lag_40', 'lag_60']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "jyg0_ZuVEVQ5",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"transaction_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": features, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4\n",
    "    \n",
    "}\n",
    "\n",
    "e_train_gym = StockPortfolioEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HTlOf8SJGdkl",
    "outputId": "1141154d-5cdc-41ba-f485-4d6e93680049",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eKIu5UPlPnk"
   },
   "source": [
    "# <a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "VDxU0iCEGdnb",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "agent = DRLAgent(env = env_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdPe8uzflbXe"
   },
   "source": [
    "### Model 1: **A2C**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1tORf1fIcQ2",
    "outputId": "4a1b885a-ef5d-4dff-f24f-c9468347067b",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0002}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
    "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DazEdrMpIdyz",
    "outputId": "540c591c-e0da-43f8-ae08-989d427a8c79",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 229       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | 2.79e+08  |\n",
      "|    reward             | 1303658.8 |\n",
      "|    std                | 0.998     |\n",
      "|    value_loss         | 1.8e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 236       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 3.72e+08  |\n",
      "|    reward             | 1759000.1 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 3.33e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2008734.8275614092\n",
      "Sharpe:  1.1904096924391037\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | 2.33e+08  |\n",
      "|    reward             | 1192144.2 |\n",
      "|    std                | 0.998     |\n",
      "|    value_loss         | 1.43e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 217       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 3.03e+08  |\n",
      "|    reward             | 1463715.1 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 2.16e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1831339.375059806\n",
      "Sharpe:  1.0401068442682275\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 213       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 2.18e+08  |\n",
      "|    reward             | 1058555.4 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 1.13e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 215       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 2.85e+08  |\n",
      "|    reward             | 1355068.9 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 1.91e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1974936.0031470314\n",
      "Sharpe:  1.153429404654777\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 207      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 1.86e+08 |\n",
      "|    reward             | 934684.9 |\n",
      "|    std                | 0.996    |\n",
      "|    value_loss         | 8.64e+12 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 210       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 2.38e+08  |\n",
      "|    reward             | 1128903.0 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 1.48e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 212       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 3.82e+08  |\n",
      "|    reward             | 1832616.5 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 3.52e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1849552.4774057425\n",
      "Sharpe:  1.0651463404307577\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 210       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 23        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 2.41e+08  |\n",
      "|    reward             | 1199982.0 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 1.54e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 211       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 3.63e+08  |\n",
      "|    reward             | 1659114.1 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 2.91e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1961513.4202733913\n",
      "Sharpe:  1.1572635935422553\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 207       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.7     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 2.49e+08  |\n",
      "|    reward             | 1220358.2 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 1.54e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 208       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 3.42e+08  |\n",
      "|    reward             | 1633930.8 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 2.99e+13  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2153482.8828611607\n",
      "Sharpe:  1.3015280000300582\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 207       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 33        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 2.28e+08  |\n",
      "|    reward             | 1037495.6 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 1.16e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 208       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 2.57e+08  |\n",
      "|    reward             | 1209182.2 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 1.57e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1813850.242675839\n",
      "Sharpe:  1.0339464789769675\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 203      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 1.99e+08 |\n",
      "|    reward             | 897480.1 |\n",
      "|    std                | 0.994    |\n",
      "|    value_loss         | 9.39e+12 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 203       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.7     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 2.29e+08  |\n",
      "|    reward             | 1168924.5 |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 1.45e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 204       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 3.67e+08  |\n",
      "|    reward             | 1782512.4 |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 3.32e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1807794.8780587877\n",
      "Sharpe:  1.0348659674460068\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 2.61e+08  |\n",
      "|    reward             | 1220855.6 |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 1.45e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 3.35e+08  |\n",
      "|    reward             | 1606955.9 |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 2.7e+13   |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1817209.895145311\n",
      "Sharpe:  1.0446275166799661\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 2.4e+08   |\n",
      "|    reward             | 1195022.1 |\n",
      "|    std                | 0.993     |\n",
      "|    value_loss         | 1.46e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | 2.62e+08  |\n",
      "|    reward             | 1415823.4 |\n",
      "|    std                | 0.993     |\n",
      "|    value_loss         | 1.98e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1812303.5054569903\n",
      "Sharpe:  1.0405873048241876\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.6     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 1.93e+08  |\n",
      "|    reward             | 1002640.4 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 1.07e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.6     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 2.37e+08  |\n",
      "|    reward             | 1186388.9 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 1.43e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1778334.5691607315\n",
      "Sharpe:  0.9957696898528304\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.5     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | 2.15e+08  |\n",
      "|    reward             | 981885.25 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 1.07e+13  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 64        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 2.66e+08  |\n",
      "|    reward             | 1263524.9 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 1.83e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 3.89e+08  |\n",
      "|    reward             | 1889789.1 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 3.85e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1926602.8829664374\n",
      "Sharpe:  1.1309201585181063\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 2.55e+08  |\n",
      "|    reward             | 1157796.5 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 1.5e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 71        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | 3.19e+08  |\n",
      "|    reward             | 1541082.9 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 2.47e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1779268.8764347557\n",
      "Sharpe:  0.9957885662298743\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 2.57e+08  |\n",
      "|    reward             | 1119701.8 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 1.35e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | 2.85e+08  |\n",
      "|    reward             | 1393410.2 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 2.12e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1977995.1063393927\n",
      "Sharpe:  1.1659470152067648\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 2.03e+08  |\n",
      "|    reward             | 1015482.0 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 1.12e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 203       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 81        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 2.2e+08   |\n",
      "|    reward             | 1206904.4 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 1.33e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1962225.4077140589\n",
      "Sharpe:  1.1540367929086466\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 199      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 1.94e+08 |\n",
      "|    reward             | 989261.2 |\n",
      "|    std                | 0.99     |\n",
      "|    value_loss         | 1.02e+13 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 198       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 88        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 2.68e+08  |\n",
      "|    reward             | 1269330.6 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 1.67e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 196       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 91        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | 3.73e+08  |\n",
      "|    reward             | 1759755.0 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 3.34e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1773562.3777381312\n",
      "Sharpe:  0.9843053457171199\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 195       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 94        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 2.64e+08  |\n",
      "|    reward             | 1203113.0 |\n",
      "|    std                | 0.989     |\n",
      "|    value_loss         | 1.6e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 195       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 97        |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 3.56e+08  |\n",
      "|    reward             | 1705836.0 |\n",
      "|    std                | 0.989     |\n",
      "|    value_loss         | 3.03e+13  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1971454.68350671\n",
      "Sharpe:  1.150317405846422\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 196       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 99        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 2.18e+08  |\n",
      "|    reward             | 1085754.4 |\n",
      "|    std                | 0.989     |\n",
      "|    value_loss         | 1.27e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 196       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 101       |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 2.85e+08  |\n",
      "|    reward             | 1369302.5 |\n",
      "|    std                | 0.989     |\n",
      "|    value_loss         | 2e+13     |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1777662.1745755547\n",
      "Sharpe:  0.9960745685156259\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 197       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 103       |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 2.23e+08  |\n",
      "|    reward             | 1072119.6 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 1.21e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 198       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | 2.1e+08   |\n",
      "|    reward             | 1087151.5 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 1.26e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1894960.578705396\n",
      "Sharpe:  1.0894817386820461\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 107       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | 2.02e+08  |\n",
      "|    reward             | 948931.0  |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 9.17e+12  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 109       |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | 2.32e+08  |\n",
      "|    reward             | 1238103.1 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 1.48e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 111       |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | 3.74e+08  |\n",
      "|    reward             | 1783335.0 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 3.44e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1829133.8495823168\n",
      "Sharpe:  1.0214323782125003\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 113       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.3     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 2.54e+08  |\n",
      "|    reward             | 1182459.5 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 1.51e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 203       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 115       |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | 3.69e+08  |\n",
      "|    reward             | 1685943.6 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 2.99e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1872032.7022826863\n",
      "Sharpe:  1.0600815400015704\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 203       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 117       |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.3     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 2.26e+08  |\n",
      "|    reward             | 1073035.4 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 1.23e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 204       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 120       |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.2     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | 2.66e+08  |\n",
      "|    reward             | 1320886.9 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 1.75e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1820189.3778381997\n",
      "Sharpe:  1.014616731491876\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 204        |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 122        |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -70.2      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | 2.33e+08   |\n",
      "|    reward             | 1041098.25 |\n",
      "|    std                | 0.986      |\n",
      "|    value_loss         | 1.16e+13   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 205       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 124       |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 2.4e+08   |\n",
      "|    reward             | 1058120.2 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 1.33e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1825488.1958972972\n",
      "Sharpe:  1.0256685393718505\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 206      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 126      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 2.04e+08 |\n",
      "|    reward             | 963178.4 |\n",
      "|    std                | 0.986    |\n",
      "|    value_loss         | 9.93e+12 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 206       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 128       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | 2.85e+08  |\n",
      "|    reward             | 1288108.4 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 1.96e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 207       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 130       |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 3.44e+08  |\n",
      "|    reward             | 1759702.0 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 3.16e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1771270.2860914606\n",
      "Sharpe:  0.9753269027913468\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 208       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 132       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.2     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | 2.37e+08  |\n",
      "|    reward             | 1157001.2 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 1.4e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 208       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 133       |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | 3.43e+08  |\n",
      "|    reward             | 1548035.2 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 2.53e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1724908.0477790881\n",
      "Sharpe:  0.9338867159160195\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 209       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 136       |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.2     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | 2.27e+08  |\n",
      "|    reward             | 1116780.5 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 1.31e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 209       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 138       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | 2.69e+08  |\n",
      "|    reward             | 1337545.2 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 1.9e+13   |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1790056.269989225\n",
      "Sharpe:  0.9859950085967731\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 210       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 140       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 2.15e+08  |\n",
      "|    reward             | 1037986.8 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 1.07e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 210       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 142       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | 2.36e+08  |\n",
      "|    reward             | 1180230.5 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 1.46e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1804068.4973872562\n",
      "Sharpe:  1.009976470286249\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 211       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 144       |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | 2.07e+08  |\n",
      "|    reward             | 972120.06 |\n",
      "|    std                | 0.983     |\n",
      "|    value_loss         | 1.05e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 211       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.1     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | 2.62e+08  |\n",
      "|    reward             | 1326002.2 |\n",
      "|    std                | 0.983     |\n",
      "|    value_loss         | 1.8e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 212       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 148       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 3.63e+08  |\n",
      "|    reward             | 1691348.2 |\n",
      "|    std                | 0.982     |\n",
      "|    value_loss         | 2.95e+13  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1781088.034064995\n",
      "Sharpe:  0.958603988257336\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 212       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 150       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70       |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 2.47e+08  |\n",
      "|    reward             | 1176368.9 |\n",
      "|    std                | 0.982     |\n",
      "|    value_loss         | 1.5e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 213       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 152       |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | 3.01e+08  |\n",
      "|    reward             | 1495723.5 |\n",
      "|    std                | 0.982     |\n",
      "|    value_loss         | 2.39e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1730610.9457397093\n",
      "Sharpe:  0.9295841602867555\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 213       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 154       |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | 2.31e+08  |\n",
      "|    reward             | 1097601.6 |\n",
      "|    std                | 0.981     |\n",
      "|    value_loss         | 1.27e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 214       |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 156       |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.9     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | 2.62e+08  |\n",
      "|    reward             | 1266013.6 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 1.6e+13   |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1865242.2361113173\n",
      "Sharpe:  1.053889590534441\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 214        |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 158        |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -69.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | 1.98e+08   |\n",
      "|    reward             | 1016894.06 |\n",
      "|    std                | 0.98       |\n",
      "|    value_loss         | 1.08e+13   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 214       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 160       |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.9     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | 2.55e+08  |\n",
      "|    reward             | 1165169.8 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 1.51e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1877847.1620320969\n",
      "Sharpe:  1.0664381544945096\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 215       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 162       |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.9     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | 1.99e+08  |\n",
      "|    reward             | 981621.25 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 1.05e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 215       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 164       |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 2.81e+08  |\n",
      "|    reward             | 1375600.5 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 2e+13     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 216       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 166       |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | 3.66e+08  |\n",
      "|    reward             | 1816493.9 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 3.38e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1929356.5572114899\n",
      "Sharpe:  1.1029509881324824\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 216       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 168       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | 2.39e+08  |\n",
      "|    reward             | 1124082.5 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 1.43e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 217       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 170       |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | 3.26e+08  |\n",
      "|    reward             | 1586875.6 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 2.6e+13   |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1879135.285732014\n",
      "Sharpe:  1.0773795205884678\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 217       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 172       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 2.27e+08  |\n",
      "|    reward             | 1111985.6 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 1.26e+13  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 217       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 174       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.9     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | 2.88e+08  |\n",
      "|    reward             | 1323974.6 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 1.87e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1916169.881919747\n",
      "Sharpe:  1.0942982800727572\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 218       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 176       |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | 2.03e+08  |\n",
      "|    reward             | 987581.7  |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 1.04e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 218       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 178       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | 2.47e+08  |\n",
      "|    reward             | 1246159.4 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 1.6e+13   |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1857227.7279187045\n",
      "Sharpe:  1.0643407448333349\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 218       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 180       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | 2.26e+08  |\n",
      "|    reward             | 1013436.6 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 1.12e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 218       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 182       |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.9     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | 2.9e+08   |\n",
      "|    reward             | 1348507.4 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 1.94e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 219       |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 184       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | 3.35e+08  |\n",
      "|    reward             | 1680546.4 |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 2.87e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1810822.1112681304\n",
      "Sharpe:  1.0226417071903147\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 219       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 186       |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | 2.46e+08  |\n",
      "|    reward             | 1190335.5 |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 1.5e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 188       |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | 3.02e+08  |\n",
      "|    reward             | 1488737.0 |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 2.39e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1838230.1292304706\n",
      "Sharpe:  1.0347033030392387\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 190       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | 2.15e+08  |\n",
      "|    reward             | 1046724.1 |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 1.17e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 192       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | 2.65e+08  |\n",
      "|    reward             | 1211046.0 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 1.54e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1774729.3675071837\n",
      "Sharpe:  0.9870252709455907\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 194       |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | 1.91e+08  |\n",
      "|    reward             | 975184.0  |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 9.54e+12  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 196       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 2.38e+08  |\n",
      "|    reward             | 1210272.5 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 1.53e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1861145.8577673815\n",
      "Sharpe:  1.0416497394680593\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 8800       |\n",
      "|    time_elapsed       | 198        |\n",
      "|    total_timesteps    | 44000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -69.8      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0002     |\n",
      "|    n_updates          | 8799       |\n",
      "|    policy_loss        | 1.61e+08   |\n",
      "|    reward             | 1016614.25 |\n",
      "|    std                | 0.977      |\n",
      "|    value_loss         | 6.19e+12   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 200       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 2.83e+08  |\n",
      "|    reward             | 1294108.9 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 1.69e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 222       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 202       |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | 3.5e+08   |\n",
      "|    reward             | 1660912.8 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 2.86e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1894217.983325682\n",
      "Sharpe:  1.083082270913944\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 222       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 204       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.7     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 2.39e+08  |\n",
      "|    reward             | 1166652.1 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 1.5e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 222       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 206       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 3.01e+08  |\n",
      "|    reward             | 1465935.6 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 2.29e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1833023.216111942\n",
      "Sharpe:  1.0261902882509235\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 222       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 208       |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.7     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | 2.18e+08  |\n",
      "|    reward             | 1064432.1 |\n",
      "|    std                | 0.975     |\n",
      "|    value_loss         | 1.21e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 223       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 210       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 2.55e+08  |\n",
      "|    reward             | 1233680.4 |\n",
      "|    std                | 0.975     |\n",
      "|    value_loss         | 1.65e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1845902.1147466283\n",
      "Sharpe:  1.036705826347966\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 223      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 1.97e+08 |\n",
      "|    reward             | 942203.2 |\n",
      "|    std                | 0.975    |\n",
      "|    value_loss         | 9.32e+12 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 223       |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 214       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.7     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | 2.34e+08  |\n",
      "|    reward             | 1238269.9 |\n",
      "|    std                | 0.975     |\n",
      "|    value_loss         | 1.46e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 216       |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 4e+08     |\n",
      "|    reward             | 2004161.4 |\n",
      "|    std                | 0.975     |\n",
      "|    value_loss         | 4.19e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2007708.265413238\n",
      "Sharpe:  1.1765519101161883\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 218       |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | 2.8e+08   |\n",
      "|    reward             | 1236303.8 |\n",
      "|    std                | 0.974     |\n",
      "|    value_loss         | 1.58e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 220       |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | 3.36e+08  |\n",
      "|    reward             | 1592410.1 |\n",
      "|    std                | 0.974     |\n",
      "|    value_loss         | 2.73e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1844618.7629033232\n",
      "Sharpe:  1.0491252852144755\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 222       |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | 2.47e+08  |\n",
      "|    reward             | 1208284.5 |\n",
      "|    std                | 0.974     |\n",
      "|    value_loss         | 1.48e+13  |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                                tb_log_name='a2c',\n",
    "                                total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "cfhURI26P_Nr",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "trained_a2c.save('trained_models/trained_a2c.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvrqTro3lhAh"
   },
   "source": [
    "### Model 2: **PPO**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kVXta7jVKMhV",
    "outputId": "619c0909-eb34-43d5-bcd6-3a78ec4c74aa",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.005,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z5XlUIszKUGx",
    "outputId": "974eec9d-10a9-422d-cc35-0318743bf91a",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1717287.5065464734\n",
      "Sharpe:  0.9340859152387432\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 370       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 5         |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 1579130.4 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1870491.5513849333\n",
      "Sharpe:  1.075526135645024\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1833199.0750782813\n",
      "Sharpe:  1.0457958856959144\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 324       |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 12        |\n",
      "|    total_timesteps      | 4096      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | -3.58e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.05e+14  |\n",
      "|    n_updates            | 10        |\n",
      "|    policy_gradient_loss | -2.49e-06 |\n",
      "|    reward               | 1200323.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.05e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1865199.039895161\n",
      "Sharpe:  1.070286728554092\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1985512.9839328795\n",
      "Sharpe:  1.1750311041878057\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 316       |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 19        |\n",
      "|    total_timesteps      | 6144      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.12e+14  |\n",
      "|    n_updates            | 20        |\n",
      "|    policy_gradient_loss | -2.45e-06 |\n",
      "|    reward               | 1254534.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.48e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1832810.1991555612\n",
      "Sharpe:  1.0411889052738081\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1738842.8917795934\n",
      "Sharpe:  0.9602133935654269\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 309       |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 26        |\n",
      "|    total_timesteps      | 8192      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.52e+14  |\n",
      "|    n_updates            | 30        |\n",
      "|    policy_gradient_loss | -1.45e-06 |\n",
      "|    reward               | 1085874.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.85e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1818684.6853265867\n",
      "Sharpe:  1.037937844030573\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1709644.9321719701\n",
      "Sharpe:  0.9318307810162254\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 305       |\n",
      "|    iterations           | 5         |\n",
      "|    time_elapsed         | 33        |\n",
      "|    total_timesteps      | 10240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.21e+14  |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -1.88e-06 |\n",
      "|    reward               | 986516.94 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.39e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1997468.645164774\n",
      "Sharpe:  1.1764117254378066\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 307       |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 39        |\n",
      "|    total_timesteps      | 12288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.28e+14  |\n",
      "|    n_updates            | 50        |\n",
      "|    policy_gradient_loss | -1.57e-06 |\n",
      "|    reward               | 1565643.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.46e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1787510.1442250689\n",
      "Sharpe:  1.0036797754647093\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1628362.6452106645\n",
      "Sharpe:  0.8557875890245858\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 304       |\n",
      "|    iterations           | 7         |\n",
      "|    time_elapsed         | 47        |\n",
      "|    total_timesteps      | 14336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.22e+14  |\n",
      "|    n_updates            | 60        |\n",
      "|    policy_gradient_loss | -1.74e-06 |\n",
      "|    reward               | 1332810.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.63e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1834058.3155482456\n",
      "Sharpe:  1.0506078281539495\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1829769.2890006437\n",
      "Sharpe:  1.040726944859566\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 300       |\n",
      "|    iterations           | 8         |\n",
      "|    time_elapsed         | 54        |\n",
      "|    total_timesteps      | 16384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.92e+14  |\n",
      "|    n_updates            | 70        |\n",
      "|    policy_gradient_loss | -2e-06    |\n",
      "|    reward               | 1318365.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.95e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2006992.4313284978\n",
      "Sharpe:  1.1842196485868066\n",
      "=================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1781424.407846242\n",
      "Sharpe:  0.9968086850565152\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 301       |\n",
      "|    iterations           | 9         |\n",
      "|    time_elapsed         | 61        |\n",
      "|    total_timesteps      | 18432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.37e+14  |\n",
      "|    n_updates            | 80        |\n",
      "|    policy_gradient_loss | -2.08e-06 |\n",
      "|    reward               | 1131934.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.68e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1827049.5291141437\n",
      "Sharpe:  1.0309835211115124\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1791287.2373710796\n",
      "Sharpe:  1.0113596584272204\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 302       |\n",
      "|    iterations           | 10        |\n",
      "|    time_elapsed         | 67        |\n",
      "|    total_timesteps      | 20480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.2e+14   |\n",
      "|    n_updates            | 90        |\n",
      "|    policy_gradient_loss | -2.06e-06 |\n",
      "|    reward               | 1040861.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.8e+14   |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1747213.2119340447\n",
      "Sharpe:  0.9673756415512935\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 303       |\n",
      "|    iterations           | 11        |\n",
      "|    time_elapsed         | 74        |\n",
      "|    total_timesteps      | 22528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.3e+14   |\n",
      "|    n_updates            | 100       |\n",
      "|    policy_gradient_loss | -1.6e-06  |\n",
      "|    reward               | 1794317.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.42e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1832055.9383183182\n",
      "Sharpe:  1.0442770089279998\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1775107.704155583\n",
      "Sharpe:  0.9804035054204481\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 304       |\n",
      "|    iterations           | 12        |\n",
      "|    time_elapsed         | 80        |\n",
      "|    total_timesteps      | 24576     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.26e+14  |\n",
      "|    n_updates            | 110       |\n",
      "|    policy_gradient_loss | -1.39e-06 |\n",
      "|    reward               | 1475151.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.47e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1831011.577643992\n",
      "Sharpe:  1.0494098494047936\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1769681.8770600853\n",
      "Sharpe:  0.9816081252810024\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 304       |\n",
      "|    iterations           | 13        |\n",
      "|    time_elapsed         | 87        |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.01e+14  |\n",
      "|    n_updates            | 120       |\n",
      "|    policy_gradient_loss | -1.97e-06 |\n",
      "|    reward               | 1085263.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.04e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1874891.988790319\n",
      "Sharpe:  1.0713217177058565\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1776633.2254305996\n",
      "Sharpe:  0.9903177745442259\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 304       |\n",
      "|    iterations           | 14        |\n",
      "|    time_elapsed         | 94        |\n",
      "|    total_timesteps      | 28672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.15e+14  |\n",
      "|    n_updates            | 130       |\n",
      "|    policy_gradient_loss | -1.37e-06 |\n",
      "|    reward               | 1112251.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.42e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715638.5071158924\n",
      "Sharpe:  0.9449022877014657\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1872970.4303039475\n",
      "Sharpe:  1.0774343385335703\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 304       |\n",
      "|    iterations           | 15        |\n",
      "|    time_elapsed         | 100       |\n",
      "|    total_timesteps      | 30720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.11e+14  |\n",
      "|    n_updates            | 140       |\n",
      "|    policy_gradient_loss | -2.16e-06 |\n",
      "|    reward               | 1040306.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.42e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1816827.1167968756\n",
      "Sharpe:  1.0334019095782225\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1862026.963362048\n",
      "Sharpe:  1.0566606111618422\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 304       |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 107       |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.25e+14  |\n",
      "|    n_updates            | 150       |\n",
      "|    policy_gradient_loss | -1.38e-06 |\n",
      "|    reward               | 972078.5  |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.48e+14  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1871317.3149154296\n",
      "Sharpe:  1.0763056094842542\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 305       |\n",
      "|    iterations           | 17        |\n",
      "|    time_elapsed         | 114       |\n",
      "|    total_timesteps      | 34816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.26e+14  |\n",
      "|    n_updates            | 160       |\n",
      "|    policy_gradient_loss | -3.03e-06 |\n",
      "|    reward               | 1641280.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.67e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1845972.7199464387\n",
      "Sharpe:  1.0510562904828071\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1910145.4525502946\n",
      "Sharpe:  1.110080720577876\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 305       |\n",
      "|    iterations           | 18        |\n",
      "|    time_elapsed         | 120       |\n",
      "|    total_timesteps      | 36864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.29e+14  |\n",
      "|    n_updates            | 170       |\n",
      "|    policy_gradient_loss | -1.98e-06 |\n",
      "|    reward               | 1201849.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.56e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1717700.636928407\n",
      "Sharpe:  0.9437430660687158\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1868379.7889437887\n",
      "Sharpe:  1.0701095090312038\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 305       |\n",
      "|    iterations           | 19        |\n",
      "|    time_elapsed         | 127       |\n",
      "|    total_timesteps      | 38912     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.13e+14  |\n",
      "|    n_updates            | 180       |\n",
      "|    policy_gradient_loss | -1.57e-06 |\n",
      "|    reward               | 1308419.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.51e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1972999.9864385126\n",
      "Sharpe:  1.1535515798083829\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1865299.4875370748\n",
      "Sharpe:  1.0585971850140588\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 305       |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 133       |\n",
      "|    total_timesteps      | 40960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.32e+14  |\n",
      "|    n_updates            | 190       |\n",
      "|    policy_gradient_loss | -2.37e-06 |\n",
      "|    reward               | 1157562.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.61e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1799685.0118731572\n",
      "Sharpe:  1.0095174054636267\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1825658.7993129129\n",
      "Sharpe:  1.0169574447772312\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 305       |\n",
      "|    iterations           | 21        |\n",
      "|    time_elapsed         | 140       |\n",
      "|    total_timesteps      | 43008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.36e+14  |\n",
      "|    n_updates            | 200       |\n",
      "|    policy_gradient_loss | -1.66e-06 |\n",
      "|    reward               | 975296.06 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.91e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2029973.1053851286\n",
      "Sharpe:  1.199509540982824\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 306       |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 146       |\n",
      "|    total_timesteps      | 45056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.25e+14  |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | -2.02e-06 |\n",
      "|    reward               | 1704170.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.63e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1726399.4727187327\n",
      "Sharpe:  0.9372082591681806\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1932586.9430424762\n",
      "Sharpe:  1.140216400763619\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 306       |\n",
      "|    iterations           | 23        |\n",
      "|    time_elapsed         | 153       |\n",
      "|    total_timesteps      | 47104     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.36e+14  |\n",
      "|    n_updates            | 220       |\n",
      "|    policy_gradient_loss | -1.7e-06  |\n",
      "|    reward               | 1374439.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.82e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1713073.5700956252\n",
      "Sharpe:  0.9310092782788219\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1927858.8377998369\n",
      "Sharpe:  1.103313798096389\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 306       |\n",
      "|    iterations           | 24        |\n",
      "|    time_elapsed         | 160       |\n",
      "|    total_timesteps      | 49152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.33e+14  |\n",
      "|    n_updates            | 230       |\n",
      "|    policy_gradient_loss | -1.68e-06 |\n",
      "|    reward               | 1333330.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.42e+14  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1951416.2481146294\n",
      "Sharpe:  1.1405973015405837\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1716500.099729747\n",
      "Sharpe:  0.9304470943289785\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 306       |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 167       |\n",
      "|    total_timesteps      | 51200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.46e+14  |\n",
      "|    n_updates            | 240       |\n",
      "|    policy_gradient_loss | -2.14e-06 |\n",
      "|    reward               | 1157090.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.64e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2074720.3590155914\n",
      "Sharpe:  1.2242286050752906\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1732712.5895548037\n",
      "Sharpe:  0.9558921084547132\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 306       |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 173       |\n",
      "|    total_timesteps      | 53248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.27e+14  |\n",
      "|    n_updates            | 250       |\n",
      "|    policy_gradient_loss | -1.84e-06 |\n",
      "|    reward               | 1021036.7 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.49e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1875825.9267712412\n",
      "Sharpe:  1.0802405722446677\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1810915.4708204437\n",
      "Sharpe:  1.0278187083152852\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 306        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 180        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0        |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -70.9      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 2.38e+14   |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -2.07e-06  |\n",
      "|    reward               | 1001833.25 |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 4.74e+14   |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1908704.6189144088\n",
      "Sharpe:  1.093492717792878\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 307       |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 186       |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.28e+14  |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | -1.84e-06 |\n",
      "|    reward               | 1600014.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.77e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1840517.923980351\n",
      "Sharpe:  1.0424870043127985\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1751686.8448765462\n",
      "Sharpe:  0.9610823576137542\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 307       |\n",
      "|    iterations           | 29        |\n",
      "|    time_elapsed         | 193       |\n",
      "|    total_timesteps      | 59392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.09e+14  |\n",
      "|    n_updates            | 280       |\n",
      "|    policy_gradient_loss | -1.94e-06 |\n",
      "|    reward               | 1227752.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.41e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1815645.7409203518\n",
      "Sharpe:  1.0191330885206626\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1855458.2922626988\n",
      "Sharpe:  1.0571062132430167\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 307       |\n",
      "|    iterations           | 30        |\n",
      "|    time_elapsed         | 199       |\n",
      "|    total_timesteps      | 61440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.11e+14  |\n",
      "|    n_updates            | 290       |\n",
      "|    policy_gradient_loss | -1.54e-06 |\n",
      "|    reward               | 1299919.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.26e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1741038.4200851948\n",
      "Sharpe:  0.9585642197518794\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1850369.6508303208\n",
      "Sharpe:  1.0542458592928994\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 307       |\n",
      "|    iterations           | 31        |\n",
      "|    time_elapsed         | 206       |\n",
      "|    total_timesteps      | 63488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.25e+14  |\n",
      "|    n_updates            | 300       |\n",
      "|    policy_gradient_loss | -1.13e-06 |\n",
      "|    reward               | 1152716.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.48e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1832755.3316960286\n",
      "Sharpe:  1.0419468010632884\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1682083.7541129824\n",
      "Sharpe:  0.9002783962731168\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 307       |\n",
      "|    iterations           | 32        |\n",
      "|    time_elapsed         | 213       |\n",
      "|    total_timesteps      | 65536     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.28e+14  |\n",
      "|    n_updates            | 310       |\n",
      "|    policy_gradient_loss | -1.81e-06 |\n",
      "|    reward               | 929353.4  |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.45e+14  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1852204.3123942674\n",
      "Sharpe:  1.0535045268392096\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 308       |\n",
      "|    iterations           | 33        |\n",
      "|    time_elapsed         | 219       |\n",
      "|    total_timesteps      | 67584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.26e+14  |\n",
      "|    n_updates            | 320       |\n",
      "|    policy_gradient_loss | -1.69e-06 |\n",
      "|    reward               | 1644545.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.44e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1751561.3109320835\n",
      "Sharpe:  0.9704898275713983\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1767214.2336517388\n",
      "Sharpe:  0.9835407240309852\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 308       |\n",
      "|    iterations           | 34        |\n",
      "|    time_elapsed         | 226       |\n",
      "|    total_timesteps      | 69632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.16e+14  |\n",
      "|    n_updates            | 330       |\n",
      "|    policy_gradient_loss | -1.85e-06 |\n",
      "|    reward               | 1296621.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.41e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1726528.687003879\n",
      "Sharpe:  0.9466339910377971\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1875656.8310132371\n",
      "Sharpe:  1.0701349860217684\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 307       |\n",
      "|    iterations           | 35        |\n",
      "|    time_elapsed         | 232       |\n",
      "|    total_timesteps      | 71680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.16e+14  |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | -1.23e-06 |\n",
      "|    reward               | 1150533.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.04e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1742398.8106374405\n",
      "Sharpe:  0.9562393041245775\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1875700.4151105026\n",
      "Sharpe:  1.0761913851467877\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 307       |\n",
      "|    iterations           | 36        |\n",
      "|    time_elapsed         | 239       |\n",
      "|    total_timesteps      | 73728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.08e+14  |\n",
      "|    n_updates            | 350       |\n",
      "|    policy_gradient_loss | -1.77e-06 |\n",
      "|    reward               | 1126010.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.51e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1762775.8717803778\n",
      "Sharpe:  0.9784157973632729\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1769867.138813268\n",
      "Sharpe:  0.9764090879631911\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 307       |\n",
      "|    iterations           | 37        |\n",
      "|    time_elapsed         | 246       |\n",
      "|    total_timesteps      | 75776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.24e+14  |\n",
      "|    n_updates            | 360       |\n",
      "|    policy_gradient_loss | -1.79e-06 |\n",
      "|    reward               | 1049467.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.57e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1755328.4543123413\n",
      "Sharpe:  0.9742166501269168\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 308       |\n",
      "|    iterations           | 38        |\n",
      "|    time_elapsed         | 252       |\n",
      "|    total_timesteps      | 77824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.14e+14  |\n",
      "|    n_updates            | 370       |\n",
      "|    policy_gradient_loss | -1.3e-06  |\n",
      "|    reward               | 1770805.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.44e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1788855.5217183158\n",
      "Sharpe:  0.9952508459543532\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1786905.253494492\n",
      "Sharpe:  1.000859063325977\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 308       |\n",
      "|    iterations           | 39        |\n",
      "|    time_elapsed         | 259       |\n",
      "|    total_timesteps      | 79872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.18e+14  |\n",
      "|    n_updates            | 380       |\n",
      "|    policy_gradient_loss | -1.75e-06 |\n",
      "|    reward               | 1444744.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.58e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1725204.2662188457\n",
      "Sharpe:  0.9426971873800369\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1770470.433924978\n",
      "Sharpe:  0.9863811758862546\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 308       |\n",
      "|    iterations           | 40        |\n",
      "|    time_elapsed         | 265       |\n",
      "|    total_timesteps      | 81920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -70.9     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.93e+14  |\n",
      "|    n_updates            | 390       |\n",
      "|    policy_gradient_loss | -2.08e-06 |\n",
      "|    reward               | 996500.6  |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.97e+14  |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "zmMmk1amUlEm",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "trained_ppo.save('trained_models/trained_ppo.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3Iuv554xYFH"
   },
   "source": [
    "### Model 3: **DDPG**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ojmppgo4LPLz",
    "outputId": "1378d445-f15c-4b2c-833e-1f84e0d78ae2",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\n",
    "\n",
    "\n",
    "model_ddpg = agent.get_model(\"ddpg\",model_kwargs = DDPG_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bWt6BIR0LT25",
    "outputId": "1cd63fbf-b7d1-4f3f-e410-77c383fb6406",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1707727.7449840084\n",
      "Sharpe:  0.956321070837711\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 17        |\n",
      "|    time_elapsed    | 261       |\n",
      "|    total_timesteps | 4512      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 8.32e+07  |\n",
      "|    critic_loss     | 1.18e+13  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 3384      |\n",
      "|    reward          | 1715006.9 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 14        |\n",
      "|    time_elapsed    | 619       |\n",
      "|    total_timesteps | 9024      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.32e+07  |\n",
      "|    critic_loss     | 2.54e+12  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 7896      |\n",
      "|    reward          | 1715006.9 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 13        |\n",
      "|    time_elapsed    | 967       |\n",
      "|    total_timesteps | 13536     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -2.52e+06 |\n",
      "|    critic_loss     | 4e+10     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 12408     |\n",
      "|    reward          | 1715006.9 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 13        |\n",
      "|    time_elapsed    | 1318      |\n",
      "|    total_timesteps | 18048     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -2.67e+07 |\n",
      "|    critic_loss     | 1.6e+12   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 16920     |\n",
      "|    reward          | 1715006.9 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 13        |\n",
      "|    time_elapsed    | 1669      |\n",
      "|    total_timesteps | 22560     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -4.53e+07 |\n",
      "|    critic_loss     | 2.53e+12  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 21432     |\n",
      "|    reward          | 1715006.9 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 13        |\n",
      "|    time_elapsed    | 2023      |\n",
      "|    total_timesteps | 27072     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -6e+07    |\n",
      "|    critic_loss     | 4.53e+12  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 25944     |\n",
      "|    reward          | 1715006.9 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 28        |\n",
      "|    fps             | 13        |\n",
      "|    time_elapsed    | 2377      |\n",
      "|    total_timesteps | 31584     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -7.15e+07 |\n",
      "|    critic_loss     | 4.58e+12  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 30456     |\n",
      "|    reward          | 1715006.9 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 32        |\n",
      "|    fps             | 13        |\n",
      "|    time_elapsed    | 2729      |\n",
      "|    total_timesteps | 36096     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -8.07e+07 |\n",
      "|    critic_loss     | 4.84e+12  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 34968     |\n",
      "|    reward          | 1715006.9 |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 36        |\n",
      "|    fps             | 13        |\n",
      "|    time_elapsed    | 3082      |\n",
      "|    total_timesteps | 40608     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -8.8e+07  |\n",
      "|    critic_loss     | 5.15e+12  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 39480     |\n",
      "|    reward          | 1715006.9 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 40        |\n",
      "|    fps             | 13        |\n",
      "|    time_elapsed    | 3434      |\n",
      "|    total_timesteps | 45120     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -9.36e+07 |\n",
      "|    critic_loss     | 5.63e+12  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 43992     |\n",
      "|    reward          | 1715006.9 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 44        |\n",
      "|    fps             | 13        |\n",
      "|    time_elapsed    | 3787      |\n",
      "|    total_timesteps | 49632     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -9.8e+07  |\n",
      "|    critic_loss     | 4.78e+12  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 48504     |\n",
      "|    reward          | 1715006.9 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1715006.8235203333\n",
      "Sharpe:  0.9669053723288912\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "x4C64xZ1UrQA",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "trained_ddpg.save('trained_models/trained_ddpg.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPEXBcm-uBJo"
   },
   "source": [
    "### Model 4: **SAC**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HaWf2QeiLqyO",
    "outputId": "054fdbb0-dee8-4595-f7e4-767eb16d9002",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0003, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.0003,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZgYVPqtKLvi3",
    "outputId": "08d13796-1f44-43e4-a2db-f6dc5119e9cb",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1687810.1175539356\n",
      "Sharpe:  0.8990522625891147\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 12        |\n",
      "|    time_elapsed    | 347       |\n",
      "|    total_timesteps | 4512      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 3.34e+08  |\n",
      "|    critic_loss     | 1.84e+13  |\n",
      "|    ent_coef        | 0.376     |\n",
      "|    ent_coef_loss   | 808       |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 4411      |\n",
      "|    reward          | 1714105.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 12        |\n",
      "|    time_elapsed    | 708       |\n",
      "|    total_timesteps | 9024      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 2.4e+08   |\n",
      "|    critic_loss     | 5.46e+12  |\n",
      "|    ent_coef        | 1.46      |\n",
      "|    ent_coef_loss   | -310      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 8923      |\n",
      "|    reward          | 1714105.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 12        |\n",
      "|    time_elapsed    | 1074      |\n",
      "|    total_timesteps | 13536     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.73e+08  |\n",
      "|    critic_loss     | 8.02e+12  |\n",
      "|    ent_coef        | 5.63      |\n",
      "|    ent_coef_loss   | -1.43e+03 |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 13435     |\n",
      "|    reward          | 1714105.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 12        |\n",
      "|    time_elapsed    | 1444      |\n",
      "|    total_timesteps | 18048     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.12e+08  |\n",
      "|    critic_loss     | 1.04e+13  |\n",
      "|    ent_coef        | 21.8      |\n",
      "|    ent_coef_loss   | -2.54e+03 |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 17947     |\n",
      "|    reward          | 1714105.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 12        |\n",
      "|    time_elapsed    | 1815      |\n",
      "|    total_timesteps | 22560     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 6.73e+07  |\n",
      "|    critic_loss     | 3.49e+12  |\n",
      "|    ent_coef        | 84.5      |\n",
      "|    ent_coef_loss   | -3.65e+03 |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 22459     |\n",
      "|    reward          | 1714105.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 12        |\n",
      "|    time_elapsed    | 2192      |\n",
      "|    total_timesteps | 27072     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 3.14e+07  |\n",
      "|    critic_loss     | 5.95e+12  |\n",
      "|    ent_coef        | 327       |\n",
      "|    ent_coef_loss   | -4.8e+03  |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 26971     |\n",
      "|    reward          | 1714105.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 28        |\n",
      "|    fps             | 12        |\n",
      "|    time_elapsed    | 2566      |\n",
      "|    total_timesteps | 31584     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.97e+07  |\n",
      "|    critic_loss     | 1.04e+12  |\n",
      "|    ent_coef        | 1.27e+03  |\n",
      "|    ent_coef_loss   | -5.89e+03 |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 31483     |\n",
      "|    reward          | 1714105.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 32        |\n",
      "|    fps             | 12        |\n",
      "|    time_elapsed    | 2939      |\n",
      "|    total_timesteps | 36096     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.37e+07  |\n",
      "|    critic_loss     | 2.74e+12  |\n",
      "|    ent_coef        | 4.9e+03   |\n",
      "|    ent_coef_loss   | -7.02e+03 |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 35995     |\n",
      "|    reward          | 1714105.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 36        |\n",
      "|    fps             | 12        |\n",
      "|    time_elapsed    | 3312      |\n",
      "|    total_timesteps | 40608     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 2.21e+08  |\n",
      "|    critic_loss     | 8.26e+12  |\n",
      "|    ent_coef        | 1.9e+04   |\n",
      "|    ent_coef_loss   | -8.14e+03 |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 40507     |\n",
      "|    reward          | 1714105.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 40        |\n",
      "|    fps             | 12        |\n",
      "|    time_elapsed    | 3687      |\n",
      "|    total_timesteps | 45120     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 9.65e+08  |\n",
      "|    critic_loss     | 2.03e+13  |\n",
      "|    ent_coef        | 7.35e+04  |\n",
      "|    ent_coef_loss   | -9.25e+03 |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 45019     |\n",
      "|    reward          | 1714105.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1714105.8015329551\n",
      "Sharpe:  0.9198465332896087\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 44        |\n",
      "|    fps             | 12        |\n",
      "|    time_elapsed    | 4061      |\n",
      "|    total_timesteps | 49632     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 3.97e+09  |\n",
      "|    critic_loss     | 1.03e+16  |\n",
      "|    ent_coef        | 2.85e+05  |\n",
      "|    ent_coef_loss   | -1.03e+04 |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 49531     |\n",
      "|    reward          | 1714105.8 |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "-nUIx62dUvfF",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "trained_sac.save('trained_models/trained_sac.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iidB5E27dfzh"
   },
   "source": [
    "### Model 5: **TD3**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XtRp1mWydkvs",
    "outputId": "90c04c04-2793-4bfc-f58c-b0df1431e061",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gustavo/anaconda3/envs/finrl/lib/python3.7/site-packages/stable_baselines3/common/buffers.py:221: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 24.21GB > 10.56GB\n",
      "  \"This system does not have apparently enough memory to store the complete \"\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "id": "argM0DtodmNL",
    "outputId": "3028f13d-2e3f-429b-87d4-ca998fb44057",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1772199.7858085996\n",
      "Sharpe:  1.0130632929593688\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 17        |\n",
      "|    time_elapsed    | 254       |\n",
      "|    total_timesteps | 4512      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.97e+08  |\n",
      "|    critic_loss     | 1.12e+14  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 3384      |\n",
      "|    reward          | 1763421.9 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 15        |\n",
      "|    time_elapsed    | 594       |\n",
      "|    total_timesteps | 9024      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.74e+08  |\n",
      "|    critic_loss     | 7.29e+13  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 7896      |\n",
      "|    reward          | 1763421.9 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 14        |\n",
      "|    time_elapsed    | 941       |\n",
      "|    total_timesteps | 13536     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.35e+08  |\n",
      "|    critic_loss     | 3.75e+13  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 12408     |\n",
      "|    reward          | 1763421.9 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 13        |\n",
      "|    time_elapsed    | 1292      |\n",
      "|    total_timesteps | 18048     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.07e+08  |\n",
      "|    critic_loss     | 1.41e+13  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 16920     |\n",
      "|    reward          | 1763421.9 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 13        |\n",
      "|    time_elapsed    | 1644      |\n",
      "|    total_timesteps | 22560     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 8.14e+07  |\n",
      "|    critic_loss     | 6.36e+12  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 21432     |\n",
      "|    reward          | 1763421.9 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 13        |\n",
      "|    time_elapsed    | 1996      |\n",
      "|    total_timesteps | 27072     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 5.93e+07  |\n",
      "|    critic_loss     | 2.2e+12   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 25944     |\n",
      "|    reward          | 1763421.9 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1763421.9123593213\n",
      "Sharpe:  1.0031139377505809\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "nGXdd4uEUzCk",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "trained_td3.save('trained_models/trained_td3.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2Ma6YpTlnuZ"
   },
   "source": [
    "## Trading\n",
    "Assume that we have $1,000,000 initial capital at 2019-01-01. We use the A2C model to trade Dow jones 30 stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjcp</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>...</th>\n",
       "      <th>RSI</th>\n",
       "      <th>slowk</th>\n",
       "      <th>slowd</th>\n",
       "      <th>WILLR</th>\n",
       "      <th>MACD</th>\n",
       "      <th>ROC</th>\n",
       "      <th>OBV</th>\n",
       "      <th>lag_20</th>\n",
       "      <th>lag_40</th>\n",
       "      <th>lag_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226137</th>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>32.810001</td>\n",
       "      <td>33.540001</td>\n",
       "      <td>32.669998</td>\n",
       "      <td>32.959999</td>\n",
       "      <td>28.838276</td>\n",
       "      <td>111008800.0</td>\n",
       "      <td>PETR4.SA</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.0006241287251678888, 9.547497088755112e-05...</td>\n",
       "      <td>...</td>\n",
       "      <td>48.877619</td>\n",
       "      <td>11.663715</td>\n",
       "      <td>21.048627</td>\n",
       "      <td>-83.667188</td>\n",
       "      <td>0.602634</td>\n",
       "      <td>-2.887447</td>\n",
       "      <td>5.452826e+08</td>\n",
       "      <td>0.126068</td>\n",
       "      <td>0.016343</td>\n",
       "      <td>-0.025717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226124</th>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>2.325000</td>\n",
       "      <td>2.325000</td>\n",
       "      <td>2.325000</td>\n",
       "      <td>2.325000</td>\n",
       "      <td>2.325000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.0006241287251678888, 9.547497088755112e-05...</td>\n",
       "      <td>...</td>\n",
       "      <td>38.921043</td>\n",
       "      <td>4.354930</td>\n",
       "      <td>13.115796</td>\n",
       "      <td>-88.571429</td>\n",
       "      <td>-0.028812</td>\n",
       "      <td>-3.526971</td>\n",
       "      <td>6.858070e+05</td>\n",
       "      <td>-0.006410</td>\n",
       "      <td>-0.073705</td>\n",
       "      <td>-0.043210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226138</th>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>67.870003</td>\n",
       "      <td>63.860001</td>\n",
       "      <td>66.529999</td>\n",
       "      <td>66.529999</td>\n",
       "      <td>7893400.0</td>\n",
       "      <td>RENT3.SA</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.0006241287251678888, 9.547497088755112e-05...</td>\n",
       "      <td>...</td>\n",
       "      <td>53.614327</td>\n",
       "      <td>24.679698</td>\n",
       "      <td>27.408235</td>\n",
       "      <td>-47.492652</td>\n",
       "      <td>0.844189</td>\n",
       "      <td>0.925365</td>\n",
       "      <td>1.792504e+09</td>\n",
       "      <td>0.098604</td>\n",
       "      <td>0.069098</td>\n",
       "      <td>0.158454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226141</th>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>18.350000</td>\n",
       "      <td>18.350000</td>\n",
       "      <td>17.990000</td>\n",
       "      <td>18.030001</td>\n",
       "      <td>18.030001</td>\n",
       "      <td>53975500.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.0006241287251678888, 9.547497088755112e-05...</td>\n",
       "      <td>...</td>\n",
       "      <td>70.517636</td>\n",
       "      <td>88.999256</td>\n",
       "      <td>89.503388</td>\n",
       "      <td>-8.226213</td>\n",
       "      <td>0.362687</td>\n",
       "      <td>19.246037</td>\n",
       "      <td>9.241174e+08</td>\n",
       "      <td>0.160979</td>\n",
       "      <td>0.027936</td>\n",
       "      <td>-0.018508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226101</th>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>1.640000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>1.620000</td>\n",
       "      <td>1.620000</td>\n",
       "      <td>1.620000</td>\n",
       "      <td>250843740.0</td>\n",
       "      <td>600157.SS</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.0006241287251678888, 9.547497088755112e-05...</td>\n",
       "      <td>...</td>\n",
       "      <td>42.860273</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>43.518507</td>\n",
       "      <td>-70.000036</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>-2.409636</td>\n",
       "      <td>3.093703e+10</td>\n",
       "      <td>-0.029940</td>\n",
       "      <td>-0.084746</td>\n",
       "      <td>-0.068966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date       open       high        low      close      adjcp  \\\n",
       "226137 2022-10-27  32.810001  33.540001  32.669998  32.959999  28.838276   \n",
       "226124 2022-10-27   2.325000   2.325000   2.325000   2.325000   2.325000   \n",
       "226138 2022-10-27  64.000000  67.870003  63.860001  66.529999  66.529999   \n",
       "226141 2022-10-27  18.350000  18.350000  17.990000  18.030001  18.030001   \n",
       "226101 2022-10-27   1.640000   1.650000   1.620000   1.620000   1.620000   \n",
       "\n",
       "             volume        tic  day  \\\n",
       "226137  111008800.0   PETR4.SA    3   \n",
       "226124          0.0         FL    3   \n",
       "226138    7893400.0   RENT3.SA    3   \n",
       "226141   53975500.0          T    3   \n",
       "226101  250843740.0  600157.SS    3   \n",
       "\n",
       "                                                 cov_list  ...        RSI  \\\n",
       "226137  [[0.0006241287251678888, 9.547497088755112e-05...  ...  48.877619   \n",
       "226124  [[0.0006241287251678888, 9.547497088755112e-05...  ...  38.921043   \n",
       "226138  [[0.0006241287251678888, 9.547497088755112e-05...  ...  53.614327   \n",
       "226141  [[0.0006241287251678888, 9.547497088755112e-05...  ...  70.517636   \n",
       "226101  [[0.0006241287251678888, 9.547497088755112e-05...  ...  42.860273   \n",
       "\n",
       "            slowk      slowd      WILLR      MACD        ROC           OBV  \\\n",
       "226137  11.663715  21.048627 -83.667188  0.602634  -2.887447  5.452826e+08   \n",
       "226124   4.354930  13.115796 -88.571429 -0.028812  -3.526971  6.858070e+05   \n",
       "226138  24.679698  27.408235 -47.492652  0.844189   0.925365  1.792504e+09   \n",
       "226141  88.999256  89.503388  -8.226213  0.362687  19.246037  9.241174e+08   \n",
       "226101  50.000000  43.518507 -70.000036 -0.014977  -2.409636  3.093703e+10   \n",
       "\n",
       "          lag_20    lag_40    lag_60  \n",
       "226137  0.126068  0.016343 -0.025717  \n",
       "226124 -0.006410 -0.073705 -0.043210  \n",
       "226138  0.098604  0.069098  0.158454  \n",
       "226141  0.160979  0.027936 -0.018508  \n",
       "226101 -0.029940 -0.084746 -0.068966  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "uas8U6k455sI",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "e_trade_gym = StockPortfolioEnv(df = trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "LcGYlhyal205",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53600, 21)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "Qq4W9FbSstT7",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1389457.353315982\n",
      "Sharpe:  0.5365195694411835\n",
      "=================================\n",
      "hit end!\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1527355.9604429563\n",
      "Sharpe:  0.6741866138070857\n",
      "=================================\n",
      "hit end!\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1501072.662677848\n",
      "Sharpe:  0.6426789058667638\n",
      "=================================\n",
      "hit end!\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1486022.1291474588\n",
      "Sharpe:  0.6191157130831528\n",
      "=================================\n",
      "hit end!\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1536771.3007145352\n",
      "Sharpe:  0.6492809815756594\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "#trained_sac\n",
    "#trained_ddpg\n",
    "#trained_ppo\n",
    "#trained_a2c\n",
    "#trained_td3\n",
    "\n",
    "df_daily_return, df_actions = DRLAgent.DRL_prediction(model=trained_sac,\n",
    "                        environment = e_trade_gym)\n",
    "\n",
    "df_daily_return2, df_actions2 = DRLAgent.DRL_prediction(model=trained_ddpg,\n",
    "                        environment = e_trade_gym)\n",
    "\n",
    "df_daily_return3, df_actions3 = DRLAgent.DRL_prediction(model=trained_ppo,\n",
    "                        environment = e_trade_gym)\n",
    "\n",
    "df_daily_return4, df_actions4 = DRLAgent.DRL_prediction(model=trained_a2c,\n",
    "                        environment = e_trade_gym)\n",
    "\n",
    "df_daily_return5, df_actions5 = DRLAgent.DRL_prediction(model=trained_td3,\n",
    "                        environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "vXMMG_9SdKTu",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_daily_return.to_csv('df_daily_return.csv')\n",
    "df_daily_return.to_csv('df_daily_return2.csv')\n",
    "df_daily_return.to_csv('df_daily_return3.csv')\n",
    "df_daily_return.to_csv('df_daily_return4.csv')\n",
    "df_daily_return.to_csv('df_daily_return5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "xBX3Y68o1vRG",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_actions.to_csv('df_actions.csv')\n",
    "df_actions.to_csv('df_actions2.csv')\n",
    "df_actions.to_csv('df_actions3.csv')\n",
    "df_actions.to_csv('df_actions4.csv')\n",
    "df_actions.to_csv('df_actions5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFO42LcomPUT"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAvxipWFmUe8"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "1oGu3PCa8l6L",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from pyfolio import timeseries\n",
    "DRL_strat = convert_daily_return_to_pyfolio_ts(df_daily_return5)\n",
    "perf_func = timeseries.perf_stats \n",
    "perf_stats_all = perf_func( returns=DRL_strat, \n",
    "                              factor_returns=DRL_strat, \n",
    "                                positions=None, transactions=None, turnover_denom=\"AGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "Hqvwr6SY8l9A",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============DRL Strategy Stats===========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Annual return           0.106285\n",
       "Cumulative returns      0.536771\n",
       "Annual volatility       0.181039\n",
       "Sharpe ratio            0.649281\n",
       "Calmar ratio            0.320314\n",
       "Stability               0.818021\n",
       "Max drawdown           -0.331815\n",
       "Omega ratio             1.134494\n",
       "Sortino ratio           0.886354\n",
       "Skew                   -1.030890\n",
       "Kurtosis               19.573074\n",
       "Tail ratio              1.003096\n",
       "Daily value at risk    -0.022342\n",
       "Alpha                   0.000000\n",
       "Beta                    1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"==============DRL Strategy Stats===========\")\n",
    "perf_stats_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XcWzfa6UloDM",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_daily_return.loc[0,'date'],\n",
    "        end = df_daily_return.loc[len(df_daily_return)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dp = YahooFinanceProcessor()\n",
    "#df_comp = dp.download_data(start_date = '2008-01-01',\n",
    "#                     end_date = '2021-10-31',\n",
    "#                     ticker_list = ativos, time_interval='1D')\n",
    "#\n",
    "#dates1= df_comp.query('tic == \"AAPL\"').date.tolist()\n",
    "#dates2= df_comp.query('tic == \"PETR3.SA\"').date.tolist()\n",
    "#dates_final=list(set(dates1).intersection(dates2))\n",
    "#print(len(dates1),len(dates2))\n",
    "#print(len(dates_final))\n",
    "#\n",
    "#print(df_comp.shape)\n",
    "#df_comp=df_comp[df_comp['date'].isin(dates_final)]\n",
    "#print(df_comp.shape)\n",
    "#df_comp = data_split(df_comp,'2020-07-01', '2021-10-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_comp=df_comp[['date','close','tic']]\n",
    "df_comp = df[['date','close','tic']].tail(38916)\n",
    "df_comp.set_index('date',inplace=True)\n",
    "res = df_comp.pivot(columns='tic', values='close')\n",
    "\n",
    "# Asset weights\n",
    "wts = [0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1\n",
    "      ,0.1,0.1,0.1,0.1,0.1,0.1]\n",
    "\n",
    "\n",
    "ret_data = res.pct_change()\n",
    "\n",
    "weighted_returns = (wts * ret_data)\n",
    "weighted_returns.index= pd.to_datetime(weighted_returns.index)\n",
    "weighted_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptf_return= weighted_returns.sum(axis=1,skipna=False)\n",
    "ptf_return.name= 'Portfolio Returns'\n",
    "ptf_return.index=DRL_strat.index\n",
    "ptf_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVVCMVSAmcrI"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fqSEF5PfjjT",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pyfolio\n",
    "%matplotlib inline\n",
    "\n",
    "baseline_df = get_baseline(\n",
    "        ticker='^DJI', start=df_daily_return.loc[0,'date'], end='2022-11-04'\n",
    "    )\n",
    "\n",
    "baseline_returns = get_daily_return(baseline_df, value_col_name=\"close\")\n",
    "\n",
    "with pyfolio.plotting.plotting_context(font_scale=1.1):\n",
    "        pyfolio.create_full_tear_sheet(returns = DRL_strat,\n",
    "                                       benchmark_rets=baseline_returns, set_context=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pyfolio.plotting.plotting_context(font_scale=1.1):\n",
    "        pyfolio.create_full_tear_sheet(returns = DRL_strat,\n",
    "                                       benchmark_rets=ptf_return, set_context=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "te3Ibcj5hUbz"
   },
   "source": [
    "## Min-Variance Portfolio Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1VE2eUEuhMKs",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#%pip install PyPortfolioOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0NiefM7hHn0",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lDYDIBH9hcUP",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "unique_tic = trade.tic.unique()\n",
    "unique_trade_date = trade.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qvk_pJ4iV32",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EICNukJZgnWl",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#calculate_portfolio_minimum_variance\n",
    "portfolio = pd.DataFrame(index = range(1), columns = unique_trade_date)\n",
    "initial_capital = 1000000\n",
    "portfolio.loc[0,unique_trade_date[0]] = initial_capital\n",
    "\n",
    "for i in range(len( unique_trade_date)-1):\n",
    "    df_temp = df[df.date==unique_trade_date[i]].reset_index(drop=True)\n",
    "    df_temp_next = df[df.date==unique_trade_date[i+1]].reset_index(drop=True)\n",
    "    #Sigma = risk_models.sample_cov(df_temp.return_list[0])\n",
    "    #calculate covariance matrix\n",
    "    Sigma = df_temp.return_list[0].cov()\n",
    "    #portfolio allocation\n",
    "    ef_min_var = EfficientFrontier(None, Sigma,weight_bounds=(0, 0.1))\n",
    "    #minimum variance\n",
    "    raw_weights_min_var = ef_min_var.min_volatility()\n",
    "    #get weights\n",
    "    cleaned_weights_min_var = ef_min_var.clean_weights()\n",
    "    \n",
    "    #current capital\n",
    "    cap = portfolio.iloc[0, i]\n",
    "    #current cash invested for each stock\n",
    "    current_cash = [element * cap for element in list(cleaned_weights_min_var.values())]\n",
    "    # current held shares\n",
    "    current_shares = list(np.array(current_cash)\n",
    "                                      / np.array(df_temp.close))\n",
    "    # next time period price\n",
    "    next_price = np.array(df_temp_next.close)\n",
    "    ##next_price * current share to calculate next total account value \n",
    "    portfolio.iloc[0, i+1] = np.dot(current_shares, next_price)\n",
    "    \n",
    "portfolio=portfolio.T\n",
    "portfolio.columns = ['account_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trained_sac\n",
    "#trained_ddpg\n",
    "#trained_ppo\n",
    "#trained_a2c\n",
    "sac_cumpod =(df_daily_return.daily_return+1).cumprod()-1\n",
    "ddpg_cumpod =(df_daily_return2.daily_return+1).cumprod()-1\n",
    "ppo_cumpod =(df_daily_return3.daily_return+1).cumprod()-1\n",
    "a2c_cumpod =(df_daily_return4.daily_return+1).cumprod()-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y821cLKkhCn6",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "min_var_cumpod =(portfolio.account_value.pct_change().fillna(0)+1).cumprod()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5E1X9FFGgqeZ",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dji_cumpod =(baseline_returns.fillna(0)+1).cumprod()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptf_cumpod =(ptf_return.fillna(0)+1).cumprod()-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ih6Jim-blNKY"
   },
   "source": [
    "## Plotly: DRL, Min-Variance, DJIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJRH-FX3hTRZ",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mpfgJcG5PInj",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "time_ind = pd.Series(df_daily_return.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CM-NJKa8g7Jp",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#trained_sac\n",
    "#trained_ddpg\n",
    "#trained_ppo\n",
    "#trained_a2c\n",
    "\n",
    "\n",
    "trace0_portfolio = go.Scatter(x = time_ind, y = a2c_cumpod, mode = 'lines', name = 'A2C (Portfolio Allocation)')\n",
    "trace1_portfolio = go.Scatter(x = time_ind, y = dji_cumpod, mode = 'lines', name = 'DJIA')\n",
    "trace2_portfolio = go.Scatter(x = time_ind, y = min_var_cumpod, mode = 'lines', name = 'Min-Variance')\n",
    "trace3_portfolio = go.Scatter(x = time_ind, y = ptf_cumpod, mode = 'lines', name = 'Portfolio Buy & Hold')\n",
    "trace4_portfolio = go.Scatter(x = time_ind, y = ddpg_cumpod, mode = 'lines', name = 'DDPG')\n",
    "trace5_portfolio = go.Scatter(x = time_ind, y = sac_cumpod, mode = 'lines', name = 'SAC')\n",
    "trace6_portfolio = go.Scatter(x = time_ind, y = ppo_cumpod, mode = 'lines', name = 'PPO')\n",
    "\n",
    "#trace4 = go.Scatter(x = time_ind, y = addpg_cumpod, mode = 'lines', name = 'Adaptive-DDPG')\n",
    "\n",
    "#trace2 = go.Scatter(x = time_ind, y = portfolio_cost_minv, mode = 'lines', name = 'Min-Variance')\n",
    "#trace3 = go.Scatter(x = time_ind, y = spx_value, mode = 'lines', name = 'SPX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35nVVmEuhGa1",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(trace0_portfolio)\n",
    "fig.add_trace(trace1_portfolio)\n",
    "fig.add_trace(trace2_portfolio)\n",
    "fig.add_trace(trace3_portfolio)\n",
    "fig.add_trace(trace4_portfolio)\n",
    "fig.add_trace(trace5_portfolio)\n",
    "fig.add_trace(trace6_portfolio)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=1,\n",
    "        traceorder=\"normal\",\n",
    "        font=dict(\n",
    "            family=\"sans-serif\",\n",
    "            size=15,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        bgcolor=\"White\",\n",
    "        bordercolor=\"white\",\n",
    "        borderwidth=2\n",
    "        \n",
    "    ),\n",
    ")\n",
    "#fig.update_layout(legend_orientation=\"h\")\n",
    "fig.update_layout(title={\n",
    "        #'text': \"Cumulative Return using FinRL\",\n",
    "        'y':0.85,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "#with Transaction cost\n",
    "#fig.update_layout(title =  'Quarterly Trade Date')\n",
    "fig.update_layout(\n",
    "#    margin=dict(l=20, r=20, t=20, b=20),\n",
    "\n",
    "    #paper_bgcolor='rgba(1,1,0,0)',\n",
    "    #paper_bgcolor='rgb(255,1,0)',\n",
    "    #plot_bgcolor='rgba(1, 1, 0, 0)',\n",
    "    #xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Cumulative Return\",\n",
    "xaxis={'type': 'date', \n",
    "       'tick0': time_ind[0], \n",
    "        'tickmode': 'linear', \n",
    "       'dtick': 86400000.0 *80}\n",
    "\n",
    ")\n",
    "#fig.update_xaxes(showline=True,linecolor='black',showgrid=True, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
    "#fig.update_yaxes(showline=True,linecolor='black',showgrid=True, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
    "#fig.update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='LightSteelBlue')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nXd-N5Rmh6H7",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "lvrqTro3lhAh",
    "a3Iuv554xYFH",
    "SPEXBcm-uBJo",
    "iidB5E27dfzh"
   ],
   "include_colab_link": true,
   "name": "FinRL_PortfolioAllocation_NeurIPS_2020.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "0cd912b5b8ef2e2cf6ba30a360471b623d2891ab42b88478be3d571482cb392e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
